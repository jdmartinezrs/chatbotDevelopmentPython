{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRyAccDlQUczHJiStcX+X7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdmartinezrs/chatbotDevelopmentPython/blob/main/Algoritmos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RGt7xUNWCSX",
        "outputId": "4945be61-3237-4efd-f622-e67156e0a2b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "frase = TextBlob(\"Python é uma ótima linguagem para Machine Learning\")\n",
        "print(frase.sentiment_assessments.assessments)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "npl = spacy.load('en_core_web_sm')\n",
        "frase = npl('Chatbots are revolutionizing customer service')\n",
        "\n",
        "for token in frase:#recorre palara por palabra (tokens)\n",
        "  print(token.text, token.pos_) # Muestra el texto y su categoria gramatical\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW2v245KWfLP",
        "outputId": "689515b4-b3a8-4018-df54-7b322ebe0299"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbots NOUN\n",
            "are AUX\n",
            "revolutionizing VERB\n",
            "customer NOUN\n",
            "service NOUN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download es_core_news_sm\n",
        "#Permite ejecutar comandos de terminal desde una celda\n",
        "#Descaraga el modelo linguistico\n",
        "import spacy\n",
        "\n",
        "npl = spacy.load('es_core_news_sm')\n",
        "frase = npl('¿Cómo estás?')\n",
        "\n",
        "for token in frase:#recorre palara por palabra (tokens)\n",
        "  print(token.text, token.pos_, token.lemma_) # Muestra el texto y su categoria gramatical"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jEezy4BXu9-",
        "outputId": "e5261d5f-a902-4ec1-eef4-23a357ad8109"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting es-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "¿ PUNCT ¿\n",
            "Cómo PRON cómo\n",
            "estás VERB estar\n",
            "? PUNCT ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print ([token.text for token in frase])\n",
        "\n",
        "for atributo in ['Texto','Categoria','Lema']:\n",
        "  if atributo == 'Texto':\n",
        "    print(f'{atributo}:', [token.text for token in frase])\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akSCXY7dZHod",
        "outputId": "6f7d77ba-38c5-4a3b-d878-90768b916f5f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['¿', 'Cómo', 'estás', '?']\n",
            "Texto: ['¿', 'Cómo', 'estás', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "datos = np.array([[50,3000],[10,6000],[70,6000],[40,6000]])# Datos edad e ingresos\n",
        "modelo = KMeans(n_clusters=2).fit(datos)#Agrupa en 2 grupos diferentes segun caracteristicas\n",
        "\n",
        "print(modelo.labels_)# Imprime a que grupo pertenece cada usuario (0 o 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l-BsQAmZp9x",
        "outputId": "ac667dfa-d918-4f03-a73e-5b9665b3a399"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes"
      ],
      "metadata": {
        "id": "w7k79mSWazid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "frase = ['basketball', 'aple', 'car'] # frases de entrenamiento\n",
        "etiquetas = ['deporte','food','vehicle'] # etiquetas de cada frase\n",
        "\n",
        "vectorizador = CountVectorizer()\n",
        "x = vectorizador.fit_transform(frase)\n",
        "\n",
        "modelo =  MultinomialNB()# crea el modelo de Naive Bayes\n",
        "modelo.fit(x,etiquetas)# Entrena el modelo con los vectores y etiquetas\n",
        "\n",
        "nueva = vectorizador.transform(['tenis']) # Tranforma la nueva frase\n",
        "print(modelo.predict(nueva)) # Predice a que clase pertenece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxTsPDPBa1GM",
        "outputId": "73d75b5b-f9d7-452b-df64-05a00367083f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['deporte']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLTK"
      ],
      "metadata": {
        "id": "2a0OZgCLca_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "shutil.rmtree('/root/nltk_data/tokenizers/punkt')\n",
        "\n",
        "texto = 'hola como estas'\n",
        "\n",
        "print(texto.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3OTKYAjcaR-",
        "outputId": "52354533-cf97-4953-c04a-6ef69b88891e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hola', 'como', 'estas']\n"
          ]
        }
      ]
    }
  ]
}